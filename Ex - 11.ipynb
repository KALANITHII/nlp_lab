{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n):\n",
    "    words = text.split()\n",
    "    ngrams = [tuple(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(ngrams):\n",
    "    model = defaultdict(int)\n",
    "    for ngram in ngrams:\n",
    "        model[ngram] += 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, n, max_length):\n",
    "    sentence = []\n",
    "    current_ngram = random.choice(list(model.keys()))\n",
    "    \n",
    "    for i in range(min(max_length, len(current_ngram))):\n",
    "        sentence.append(current_ngram[i])\n",
    "\n",
    "    while len(sentence) < max_length:\n",
    "        next_word = random.choices(list(model.keys()))[0][-1]\n",
    "        sentence.append(next_word)\n",
    "        current_ngram = current_ngram[1:] + (next_word,)\n",
    "    return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, test_ngrams, n):\n",
    "    log_prob = 0\n",
    "    for test_ngram in test_ngrams:\n",
    "        context = test_ngram[:-1]\n",
    "        next_word = test_ngram[-1]\n",
    "        context_ngrams = [ngram for ngram in model if ngram[:-1] == context]\n",
    "        next_word_ngrams = [ngram for ngram in context_ngrams if ngram[-1] == next_word]\n",
    "        if next_word_ngrams:\n",
    "            probability = (sum(model[ngram] for ngram in next_word_ngrams) + 1) / (sum(model[ngram] for ngram in context_ngrams) + len(model))\n",
    "        else:\n",
    "            probability = 1 / len(model)\n",
    "        log_prob += log2(probability)\n",
    "    perplexity = 2 ** (-log_prob/len(test_ngrams))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    email_text = open(\"email_text.txt\", \"r\").read()\n",
    "    newsgroups = open(\"newsgroups.txt\", \"r\").read()\n",
    "\n",
    "    email_text = preprocess_text(email_text)\n",
    "    email_ngrams = generate_ngrams(email_text, 2)\n",
    "    newsgroups_text = preprocess_text(newsgroups)\n",
    "    newsgroups_ngrams = generate_ngrams(newsgroups_text,2)\n",
    "\n",
    "    email_model = build_ngram_model(email_ngrams)\n",
    "    newsgroups_model = build_ngram_model(newsgroups_ngrams)\n",
    "\n",
    "    print(\"Most common unigrams in email text:\")\n",
    "    print(sorted(email_model.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "    print()\n",
    "    print(\"Most common unigrams in newsgroups:\")\n",
    "    print(sorted(newsgroups_model.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "    print()\n",
    "\n",
    "    print(\"Random sentence generated using email model:\")\n",
    "    print(generate_sentence(email_model, 2, 10))\n",
    "    print()\n",
    "    \n",
    "    perplexity = calculate_perplexity(email_model, newsgroups_ngrams, 2)\n",
    "    print(\"Perplexity of newsgroups corpus given email model:\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common unigrams in email text:\n",
      "[(('followup', 'meeting'), 4), (('you', 'have'), 4), (('from', 'john'), 2), (('john', 'doe'), 2), (('doe', 'johndoeemailcom'), 2)]\n",
      "\n",
      "Most common unigrams in newsgroups:\n",
      "[(('the', 'latest'), 3), (('on', 'the'), 3), (('the', 'economy'), 3), (('for', 'the'), 2), (('the', 'government'), 2)]\n",
      "\n",
      "Random sentence generated using email model:\n",
      "any updates our just team ready at project reminder followup\n",
      "\n",
      "Perplexity of newsgroups corpus given email model: 58.58659522692783\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlplab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80223e0b96b21b6ab94bb3c1b14fbef17ccb8d987f3443ee0ec439dd0b212109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
